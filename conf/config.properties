
sewer.source=pixel
sewer.sink=roll > reliable > seqfile('hdfs://localhost:9000/test/collect/%Y-%m-%d/%H00/data-%{host}-%Y%m%d-%k%M%S')

# good default buffer size for hadoop read/write buffers
# haven't seen much/any improvement w/ larger buffers
io.file.buffer.size=65536

# don't autoclose HADOOP FileSystem objects when a kill signal is trapped
fs.automatic.close=false

# source options:
#
# pixel(port)
# syslog(port)
# pipe('filename')
# tcpwrite(port)


# sink options:
#
# seqfile('hdfs://localhost:9000/test/collect/%Y-%m-%d/%H00/data-%{host}-%{rand}-%{thread}-%{nanos}-%Y%m%d-%k%M%S')
# seqfile('file:///opt/sewer/collect/%Y-%m-%d/%H00/data-%{host}-%{rand}-%{thread}-%{nanos}-%Y%m%d-%k%M%S')
# dfs("path")
# tcpwrite("host", port)
# null
# roll(sec)
# reliable
# delayed_open

# pixel source options (default values shown):

# graceful shutdown timeout
#sewer.source.pixel.graceful=1000

# jetty connetor acceptQueueSize = Number of connection requests that can be
# queued up before the operating system starts to send rejections.
#sewer.source.pixel.accept_queue=100
